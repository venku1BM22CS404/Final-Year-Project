{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7719fbe839a54a71818352ef7a49475b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02eaf19f955145a695bb1002affd3955",
              "IPY_MODEL_c5e195468564462ba2eac556d7737524",
              "IPY_MODEL_8d7976140ec247829bed9363f374cf41"
            ],
            "layout": "IPY_MODEL_f17455826b6b4212afda0e61dcef5c8f"
          }
        },
        "02eaf19f955145a695bb1002affd3955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67270b60df4a4f3787936f1ec73852c9",
            "placeholder": "​",
            "style": "IPY_MODEL_54f352e8640848c5bd58ff3f638cf629",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c5e195468564462ba2eac556d7737524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ac2567bcc934144b76b5fdebece538a",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7364dc3e84342e692ef1111666fa805",
            "value": 25
          }
        },
        "8d7976140ec247829bed9363f374cf41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce54124a1b09494f9b46014d28409549",
            "placeholder": "​",
            "style": "IPY_MODEL_c7dae6a2ac6d4cfa98c845d3376f70f7",
            "value": " 25.0/25.0 [00:00&lt;00:00, 3.24kB/s]"
          }
        },
        "f17455826b6b4212afda0e61dcef5c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67270b60df4a4f3787936f1ec73852c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f352e8640848c5bd58ff3f638cf629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ac2567bcc934144b76b5fdebece538a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7364dc3e84342e692ef1111666fa805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce54124a1b09494f9b46014d28409549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7dae6a2ac6d4cfa98c845d3376f70f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc8d05373cf4617aa505f25dcf9ab13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c7629e7b83b4393bce240e8a0597980",
              "IPY_MODEL_bc0cce30211f49ab85acdab5ec74d39f",
              "IPY_MODEL_6329e3dc8ab94842a4b6a90afb6a8b90"
            ],
            "layout": "IPY_MODEL_7d5c5361705e464a836174903829c9b7"
          }
        },
        "7c7629e7b83b4393bce240e8a0597980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b17940de5874edd91ce59823c694cac",
            "placeholder": "​",
            "style": "IPY_MODEL_548372c1103941eaa94d2cf025f2210a",
            "value": "config.json: 100%"
          }
        },
        "bc0cce30211f49ab85acdab5ec74d39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8713b8d8dd04461281e38b76adf50d7b",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02646b3667a24df8816e8d2695ecdbe0",
            "value": 615
          }
        },
        "6329e3dc8ab94842a4b6a90afb6a8b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01972b0a81694fa3985342a1126e9788",
            "placeholder": "​",
            "style": "IPY_MODEL_4d6886f2a6294ab4bdfc8e8796833b2e",
            "value": " 615/615 [00:00&lt;00:00, 89.6kB/s]"
          }
        },
        "7d5c5361705e464a836174903829c9b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b17940de5874edd91ce59823c694cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548372c1103941eaa94d2cf025f2210a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8713b8d8dd04461281e38b76adf50d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02646b3667a24df8816e8d2695ecdbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01972b0a81694fa3985342a1126e9788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6886f2a6294ab4bdfc8e8796833b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1665be4bd8d24ac18021d6b4fa416d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c05da1b166294324bee8c6e1949760da",
              "IPY_MODEL_a920b7c447694307aaab84938be73e28",
              "IPY_MODEL_f8dc0fc727f0401fba601956d778d67a"
            ],
            "layout": "IPY_MODEL_c8d33023ba1f49b08d31e6aefe2185c6"
          }
        },
        "c05da1b166294324bee8c6e1949760da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e67e4cd62334ddda5cecc13a1b94f26",
            "placeholder": "​",
            "style": "IPY_MODEL_7464724b8c5a4256bab74f92a62d4c18",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "a920b7c447694307aaab84938be73e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d90d9a2488a4eb3b2c6f20bcad41505",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f51ede464f5740e7ba0d516e8c985caf",
            "value": 5069051
          }
        },
        "f8dc0fc727f0401fba601956d778d67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fcb0445144b4e2f856c889aafce5425",
            "placeholder": "​",
            "style": "IPY_MODEL_9f164536c21641a5a4279a338fea12eb",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "c8d33023ba1f49b08d31e6aefe2185c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e67e4cd62334ddda5cecc13a1b94f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7464724b8c5a4256bab74f92a62d4c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d90d9a2488a4eb3b2c6f20bcad41505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51ede464f5740e7ba0d516e8c985caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fcb0445144b4e2f856c889aafce5425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f164536c21641a5a4279a338fea12eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f5eef868d9a4bd0bace29af54f11fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bf63fe0f0954ebcaba3aa813745cf3e",
              "IPY_MODEL_a9e7376d45dc470cbfb8e85bc9440557",
              "IPY_MODEL_c73ca1131faa487f867e2ee5ed078886"
            ],
            "layout": "IPY_MODEL_69b5fab484d74f16bb9046d07709593b"
          }
        },
        "7bf63fe0f0954ebcaba3aa813745cf3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210651912aa04281a2958f3625b22538",
            "placeholder": "​",
            "style": "IPY_MODEL_28f2f2fa12f44cabba172d8ab687a7d4",
            "value": "tokenizer.json: 100%"
          }
        },
        "a9e7376d45dc470cbfb8e85bc9440557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3a205563c4420ba0d1849f90f06ba5",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93e4f333d4c14de09b43362e7f22e030",
            "value": 9096718
          }
        },
        "c73ca1131faa487f867e2ee5ed078886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a404c4cd3084df1b0b59579c647949e",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9c1e3c9fae4a589bc7a5218d3fa922",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 61.5MB/s]"
          }
        },
        "69b5fab484d74f16bb9046d07709593b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210651912aa04281a2958f3625b22538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f2f2fa12f44cabba172d8ab687a7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c3a205563c4420ba0d1849f90f06ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e4f333d4c14de09b43362e7f22e030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a404c4cd3084df1b0b59579c647949e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9c1e3c9fae4a589bc7a5218d3fa922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dcafb6bb1394c2c8eedb7e1682403f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96c2199ce36e4983a8ddb0424a321dd7",
              "IPY_MODEL_dec6fd5e671c45c590b6263701811d5e",
              "IPY_MODEL_582437203b0f4ad7996c91f7e1501aa5"
            ],
            "layout": "IPY_MODEL_d31c8034a29b42de8f02c9b3745bc2e8"
          }
        },
        "96c2199ce36e4983a8ddb0424a321dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e1718c8c2b8486b8f25a7b4627c4318",
            "placeholder": "​",
            "style": "IPY_MODEL_3de6a1143c174dae91beeb3d520a3957",
            "value": "model.safetensors: 100%"
          }
        },
        "dec6fd5e671c45c590b6263701811d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd50685302134168bc155468e3473d6e",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_845a70f5a32c497d898aec1400e01b7b",
            "value": 1115567652
          }
        },
        "582437203b0f4ad7996c91f7e1501aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2514d7f5f5484b58822264762e144abe",
            "placeholder": "​",
            "style": "IPY_MODEL_2de72ba4014a4b0284b15b19a7dbb244",
            "value": " 1.12G/1.12G [00:11&lt;00:00, 103MB/s]"
          }
        },
        "d31c8034a29b42de8f02c9b3745bc2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e1718c8c2b8486b8f25a7b4627c4318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de6a1143c174dae91beeb3d520a3957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd50685302134168bc155468e3473d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "845a70f5a32c497d898aec1400e01b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2514d7f5f5484b58822264762e144abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de72ba4014a4b0284b15b19a7dbb244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load annotated dataset\n",
        "file_path = \"/content/hindi-english_annotated.csv\"  # Change path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display dataset structure\n",
        "print(df.head())\n",
        "print(\"\\nDataset shape:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou4ZQs7CsYmq",
        "outputId": "040ea9bc-a9ef-4a51-de79-25e0147c1246"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                                           Sentence  Category\n",
            "0   1  Tumhari smile se lagta hai sab kuch theek ho j...  Positive\n",
            "1   2  Tumhare bina toh yeh task kabhi complete hi na...  Negative\n",
            "2   3  Aaj mausam pleasant hai, toh meeting ke baad w...   Neutral\n",
            "3   4  Wah! Tumne toh project mein hamesha ki tarah a...  Negative\n",
            "4   5     Tumhari dedication sab ke liye ek example hai.  Positive\n",
            "\n",
            "Dataset shape: (300, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Remove URLs\n",
        "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)  # Remove mentions and hashtags\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters & numbers\n",
        "    text = \" \".join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df[\"cleaned_text\"] = df[\"Sentence\"].apply(preprocess_text)\n",
        "\n",
        "# Show results\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbP9UJivswiU",
        "outputId": "4b330fd3-089e-4ece-eeb2-dd07b50c04ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                                           Sentence  Category  \\\n",
            "0   1  Tumhari smile se lagta hai sab kuch theek ho j...  Positive   \n",
            "1   2  Tumhare bina toh yeh task kabhi complete hi na...  Negative   \n",
            "2   3  Aaj mausam pleasant hai, toh meeting ke baad w...   Neutral   \n",
            "3   4  Wah! Tumne toh project mein hamesha ki tarah a...  Negative   \n",
            "4   5     Tumhari dedication sab ke liye ek example hai.  Positive   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  tumhari smile se lagta hai sab kuch theek ho j...  \n",
            "1  tumhare bina toh yeh task kabhi complete hi na...  \n",
            "2  aaj mausam pleasant hai toh meeting ke baad wa...  \n",
            "3  wah tumne toh project mein hamesha ki tarah ap...  \n",
            "4      tumhari dedication sab ke liye ek example hai  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load XLM-RoBERTa tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Tokenize text\n",
        "def tokenize_text(text):\n",
        "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=50, return_tensors=\"pt\")\n",
        "\n",
        "# Apply tokenization\n",
        "df[\"tokenized_text\"] = df[\"cleaned_text\"].apply(tokenize_text)\n",
        "\n",
        "# Display results\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651,
          "referenced_widgets": [
            "7719fbe839a54a71818352ef7a49475b",
            "02eaf19f955145a695bb1002affd3955",
            "c5e195468564462ba2eac556d7737524",
            "8d7976140ec247829bed9363f374cf41",
            "f17455826b6b4212afda0e61dcef5c8f",
            "67270b60df4a4f3787936f1ec73852c9",
            "54f352e8640848c5bd58ff3f638cf629",
            "2ac2567bcc934144b76b5fdebece538a",
            "e7364dc3e84342e692ef1111666fa805",
            "ce54124a1b09494f9b46014d28409549",
            "c7dae6a2ac6d4cfa98c845d3376f70f7",
            "ccc8d05373cf4617aa505f25dcf9ab13",
            "7c7629e7b83b4393bce240e8a0597980",
            "bc0cce30211f49ab85acdab5ec74d39f",
            "6329e3dc8ab94842a4b6a90afb6a8b90",
            "7d5c5361705e464a836174903829c9b7",
            "9b17940de5874edd91ce59823c694cac",
            "548372c1103941eaa94d2cf025f2210a",
            "8713b8d8dd04461281e38b76adf50d7b",
            "02646b3667a24df8816e8d2695ecdbe0",
            "01972b0a81694fa3985342a1126e9788",
            "4d6886f2a6294ab4bdfc8e8796833b2e",
            "1665be4bd8d24ac18021d6b4fa416d7d",
            "c05da1b166294324bee8c6e1949760da",
            "a920b7c447694307aaab84938be73e28",
            "f8dc0fc727f0401fba601956d778d67a",
            "c8d33023ba1f49b08d31e6aefe2185c6",
            "8e67e4cd62334ddda5cecc13a1b94f26",
            "7464724b8c5a4256bab74f92a62d4c18",
            "2d90d9a2488a4eb3b2c6f20bcad41505",
            "f51ede464f5740e7ba0d516e8c985caf",
            "7fcb0445144b4e2f856c889aafce5425",
            "9f164536c21641a5a4279a338fea12eb",
            "0f5eef868d9a4bd0bace29af54f11fe8",
            "7bf63fe0f0954ebcaba3aa813745cf3e",
            "a9e7376d45dc470cbfb8e85bc9440557",
            "c73ca1131faa487f867e2ee5ed078886",
            "69b5fab484d74f16bb9046d07709593b",
            "210651912aa04281a2958f3625b22538",
            "28f2f2fa12f44cabba172d8ab687a7d4",
            "2c3a205563c4420ba0d1849f90f06ba5",
            "93e4f333d4c14de09b43362e7f22e030",
            "5a404c4cd3084df1b0b59579c647949e",
            "1f9c1e3c9fae4a589bc7a5218d3fa922"
          ]
        },
        "id": "jwij0LlFtDxD",
        "outputId": "63e0f582-cb47-46b9-9bf3-f0f791cf3afe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7719fbe839a54a71818352ef7a49475b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccc8d05373cf4617aa505f25dcf9ab13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1665be4bd8d24ac18021d6b4fa416d7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f5eef868d9a4bd0bace29af54f11fe8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                                           Sentence  Category  \\\n",
            "0   1  Tumhari smile se lagta hai sab kuch theek ho j...  Positive   \n",
            "1   2  Tumhare bina toh yeh task kabhi complete hi na...  Negative   \n",
            "2   3  Aaj mausam pleasant hai, toh meeting ke baad w...   Neutral   \n",
            "3   4  Wah! Tumne toh project mein hamesha ki tarah a...  Negative   \n",
            "4   5     Tumhari dedication sab ke liye ek example hai.  Positive   \n",
            "\n",
            "                                        cleaned_text  \\\n",
            "0  tumhari smile se lagta hai sab kuch theek ho j...   \n",
            "1  tumhare bina toh yeh task kabhi complete hi na...   \n",
            "2  aaj mausam pleasant hai toh meeting ke baad wa...   \n",
            "3  wah tumne toh project mein hamesha ki tarah ap...   \n",
            "4      tumhari dedication sab ke liye ek example hai   \n",
            "\n",
            "                tokenized_text  \n",
            "0  [input_ids, attention_mask]  \n",
            "1  [input_ids, attention_mask]  \n",
            "2  [input_ids, attention_mask]  \n",
            "3  [input_ids, attention_mask]  \n",
            "4  [input_ids, attention_mask]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Convert sentiment labels to numerical values\n",
        "label_map = {\"Positive\": 2, \"Neutral\": 1, \"Negative\": 0}\n",
        "df[\"label\"] = df[\"Category\"].map(label_map)\n",
        "\n",
        "# Define a PyTorch dataset class\n",
        "class HinglishDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(item[\"tokenized_text\"][\"input_ids\"]).squeeze(),\n",
        "            \"attention_mask\": torch.tensor(item[\"tokenized_text\"][\"attention_mask\"]).squeeze(),\n",
        "            \"labels\": torch.tensor(item[\"label\"], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Create dataset & dataloader\n",
        "dataset = HinglishDataset(df)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Print sample batch\n",
        "sample_batch = next(iter(dataloader))\n",
        "print(sample_batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIGLNR21tQ6O",
        "outputId": "77bb9786-107b-4c05-9189-15e7a377fc20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[     0,  38674,    161,  58269,    337,  21620,  98893,   8980,      2,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1],\n",
            "        [     0,  76021,  13452,   1563,  28484,    739,  26774,   1337,  45458,\n",
            "         127752,      2,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1],\n",
            "        [     0,   5201,     10,  39036,   4092,    739,    191,    151,   6037,\n",
            "              2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1],\n",
            "        [     0,  76021,  60213,    741,  10029,     86,  15190,  94737,   3319,\n",
            "           4323,  14461,     85,  55681,   6953,   8475,   8980,   1337,      2,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1],\n",
            "        [     0,    370,  56426,     13,  18151,   8172,  15040,  43967,  18499,\n",
            "              7,  15531,    741,     79,  11220,  30022,    739, 148070,  15531,\n",
            "              2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1],\n",
            "        [     0,    370,  56426,     13,  17309,    375,   4007,   8172,  15040,\n",
            "          65572,    741,  36049,    280,  52490,   1185,  35065,      2,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1],\n",
            "        [     0,  10029,  11416,  29806,    156,  26539, 138155,   9090,  29479,\n",
            "           2886,   3319,      2,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1],\n",
            "        [     0,  10029,     86,  92469,  18151,    298,  15787,  16730,    395,\n",
            "           1337,    337,  21620,  93766,   1337,      2,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "              1,      1,      1,      1,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0]]), 'labels': tensor([2, 2, 1, 0, 1, 0, 2, 2])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8756e678135c>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"input_ids\": torch.tensor(item[\"tokenized_text\"][\"input_ids\"]).squeeze(),\n",
            "<ipython-input-10-8756e678135c>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"attention_mask\": torch.tensor(item[\"tokenized_text\"][\"attention_mask\"]).squeeze(),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "# Define the Sentiment Classification Model\n",
        "class HinglishSentimentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HinglishSentimentModel, self).__init__()\n",
        "        self.xlm_roberta = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(768, 3)  # Output: 3 sentiment classes (Positive, Neutral, Negative)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.xlm_roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(dropout_output)\n",
        "        return logits\n",
        "\n",
        "# Initialize model\n",
        "model = HinglishSentimentModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Print model summary\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830,
          "referenced_widgets": [
            "2dcafb6bb1394c2c8eedb7e1682403f7",
            "96c2199ce36e4983a8ddb0424a321dd7",
            "dec6fd5e671c45c590b6263701811d5e",
            "582437203b0f4ad7996c91f7e1501aa5",
            "d31c8034a29b42de8f02c9b3745bc2e8",
            "0e1718c8c2b8486b8f25a7b4627c4318",
            "3de6a1143c174dae91beeb3d520a3957",
            "bd50685302134168bc155468e3473d6e",
            "845a70f5a32c497d898aec1400e01b7b",
            "2514d7f5f5484b58822264762e144abe",
            "2de72ba4014a4b0284b15b19a7dbb244"
          ]
        },
        "id": "z_DdOpGEtjkE",
        "outputId": "f044cfc5-55b1-465d-9dc7-3573888d59bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dcafb6bb1394c2c8eedb7e1682403f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HinglishSentimentModel(\n",
            "  (xlm_roberta): XLMRobertaModel(\n",
            "    (embeddings): XLMRobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): XLMRobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x XLMRobertaLayer(\n",
            "          (attention): XLMRobertaAttention(\n",
            "            (self): XLMRobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): XLMRobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): XLMRobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): XLMRobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): XLMRobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "num_epochs = 3  # Adjust based on dataset size\n",
        "num_training_steps = len(dataloader) * num_epochs\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Move model to GPU (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Training setup is ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prl-kbbtt6Ix",
        "outputId": "eea4e989-9413-49b6-c475-11888ce42c9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training setup is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, dataloader, optimizer, loss_fn, lr_scheduler, num_epochs=3):\n",
        "    model.train()  # Set model to training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "        loop = tqdm(dataloader, leave=True)\n",
        "\n",
        "        total_loss = 0\n",
        "        for batch in loop:\n",
        "            # Move batch to GPU (if available)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loop.set_description(f\"Loss: {total_loss / (loop.n + 1):.4f}\")\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "\n",
        "# Start Training\n",
        "train_model(model, dataloader, optimizer, loss_fn, lr_scheduler, num_epochs=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T4KWFzluEId",
        "outputId": "d8455655-af37-4656-c3c2-8cb842bd31fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/38 [00:00<?, ?it/s]<ipython-input-10-8756e678135c>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"input_ids\": torch.tensor(item[\"tokenized_text\"][\"input_ids\"]).squeeze(),\n",
            "<ipython-input-10-8756e678135c>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"attention_mask\": torch.tensor(item[\"tokenized_text\"][\"attention_mask\"]).squeeze(),\n",
            "Loss: 1.2753: 100%|██████████| 38/38 [06:02<00:00,  9.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 1.1716: 100%|██████████| 38/38 [05:39<00:00,  8.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 1.2146: 100%|██████████| 38/38 [05:39<00:00,  8.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            true_labels.extend(labels)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, target_names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "# Evaluate on the same dataset (for now)\n",
        "evaluate_model(model, dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVHeArJwyQSc",
        "outputId": "06050f69-4453-4720-fb27-4156c101c62c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8756e678135c>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"input_ids\": torch.tensor(item[\"tokenized_text\"][\"input_ids\"]).squeeze(),\n",
            "<ipython-input-10-8756e678135c>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"attention_mask\": torch.tensor(item[\"tokenized_text\"][\"attention_mask\"]).squeeze(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3167\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00        98\n",
            "     Neutral       0.32      1.00      0.48        95\n",
            "    Positive       0.00      0.00      0.00       107\n",
            "\n",
            "    accuracy                           0.32       300\n",
            "   macro avg       0.11      0.33      0.16       300\n",
            "weighted avg       0.10      0.32      0.15       300\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Modify HinglishDataset class to handle unlabeled data\n",
        "class HinglishDataset(Dataset):\n",
        "    def __init__(self, dataframe, labeled=True):\n",
        "        self.data = dataframe\n",
        "        self.labeled = labeled  # Flag to check if dataset has labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        data = {\n",
        "            \"input_ids\": torch.tensor(item[\"tokenized_text\"][\"input_ids\"]).squeeze(),\n",
        "            \"attention_mask\": torch.tensor(item[\"tokenized_text\"][\"attention_mask\"]).squeeze(),\n",
        "        }\n",
        "        if self.labeled:\n",
        "            data[\"labels\"] = torch.tensor(item[\"label\"], dtype=torch.long)\n",
        "        return data\n",
        "\n",
        "# Load Hinglish dataset\n",
        "file_path = \"/content/comments INDIA'S GOT LATENT  EP 10 ft. Raghu Ram _@tanmaybhat_  _@Sidwarrier_ buSdqtdn_4I.csv\"\n",
        "df_unlabeled = pd.read_csv(file_path)\n",
        "\n",
        "# Use the correct text column\n",
        "text_column = \"simpleText\"\n",
        "\n",
        "# Preprocess text\n",
        "df_unlabeled[\"cleaned_text\"] = df_unlabeled[text_column].apply(preprocess_text)\n",
        "\n",
        "# Tokenize text\n",
        "df_unlabeled[\"tokenized_text\"] = df_unlabeled[\"cleaned_text\"].apply(tokenize_text)\n",
        "\n",
        "# Create DataLoader for unlabeled dataset\n",
        "unlabeled_dataset = HinglishDataset(df_unlabeled, labeled=False)\n",
        "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Predict sentiment labels\n",
        "df_unlabeled[\"predicted_sentiment\"] = predict_sentiment(model, unlabeled_dataloader)\n",
        "\n",
        "# Save pseudo-labeled dataset\n",
        "df_unlabeled.to_csv(\"hinglish_pseudo_labeled.csv\", index=False)\n",
        "\n",
        "print(\"✅ Pseudo-labeling complete! File saved as 'hinglish_pseudo_labeled.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihY5_PGh1Vax",
        "outputId": "bee01177-7243-48cb-b024-daad0539ead4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-14b49e002bc7>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"input_ids\": torch.tensor(item[\"tokenized_text\"][\"input_ids\"]).squeeze(),\n",
            "<ipython-input-22-14b49e002bc7>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"attention_mask\": torch.tensor(item[\"tokenized_text\"][\"attention_mask\"]).squeeze(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pseudo-labeling complete! File saved as 'hinglish_pseudo_labeled.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the pseudo-labeled dataset\n",
        "df_check = pd.read_csv(\"hinglish_pseudo_labeled.csv\")\n",
        "\n",
        "# Display first few rows\n",
        "print(df_check.head())\n",
        "\n",
        "# Check if 'tokenized_text' column exists\n",
        "if \"tokenized_text\" not in df_check.columns:\n",
        "    print(\"❌ ERROR: 'tokenized_text' column is missing!\")\n",
        "\n",
        "# Check how many tokenized_text values are missing or empty\n",
        "missing_values = df_check[\"tokenized_text\"].isnull().sum()\n",
        "print(f\"⚠ Missing tokenized_text values: {missing_values}\")\n",
        "\n",
        "# Display some samples\n",
        "print(df_check[\"tokenized_text\"].sample(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSVPamme6kR8",
        "outputId": "77d8d3be-819e-45b8-a9fd-b1b911ff252a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  publishedTimeText                                         simpleText  votes  \\\n",
            "0      23 hours ago  Underrated guest Sid Warrier, Positive energy ...    804   \n",
            "1      19 hours ago                        Asli Id se aao warrior bhai     23   \n",
            "2      17 hours ago                                                Yep      1   \n",
            "3      23 hours ago  No matter how big this show has gone, seeing S...    645   \n",
            "4      16 hours ago                                    100 % right 😍🤩🙌      4   \n",
            "\n",
            "                author  isReply  isHearted  isPinned  isPaid  paidAmount  \\\n",
            "0   @HumanityNotDoomed    False      False     False   False         NaN   \n",
            "1   @sarcasticaloo2220     True      False     False   False         NaN   \n",
            "2  @himangimahajan3631     True      False     False   False         NaN   \n",
            "3            @mesatin2    False      False     False   False         NaN   \n",
            "4      @mehtasanketd07     True      False     False   False         NaN   \n",
            "\n",
            "   isSponsor  sponsorshipMonths  \\\n",
            "0       True                1.0   \n",
            "1      False                NaN   \n",
            "2      False                NaN   \n",
            "3      False                NaN   \n",
            "4      False                NaN   \n",
            "\n",
            "                                        cleaned_text  \\\n",
            "0  underrated guest sid warrier positive energy n...   \n",
            "1                        asli id se aao warrior bhai   \n",
            "2                                                yep   \n",
            "3  matter big show gone seeing samay tanmay toget...   \n",
            "4                                              right   \n",
            "\n",
            "                                      tokenized_text  predicted_sentiment  \n",
            "0  {'input_ids': tensor([[     0,   1379,   2175,...                    1  \n",
            "1  {'input_ids': tensor([[     0,  50802,   3447,...                    1  \n",
            "2  {'input_ids': tensor([[   0,  113, 4517,    2,...                    1  \n",
            "3  {'input_ids': tensor([[    0, 26866,  6957,  7...                    1  \n",
            "4  {'input_ids': tensor([[   0, 7108,    2,    1,...                    1  \n",
            "⚠ Missing tokenized_text values: 0\n",
            "561     {'input_ids': tensor([[    0, 21624, 13969,   ...\n",
            "1055    {'input_ids': tensor([[     0,  27470,   1132,...\n",
            "1167    {'input_ids': tensor([[     0,   1614,  34601,...\n",
            "233     {'input_ids': tensor([[     0,   6183,  17723,...\n",
            "3205    {'input_ids': tensor([[   0, 7639,    2,    1,...\n",
            "3928    {'input_ids': tensor([[     0,   1847,     53,...\n",
            "3932    {'input_ids': tensor([[     0,     10,    372,...\n",
            "326     {'input_ids': tensor([[     0,   1627,   1909,...\n",
            "445     {'input_ids': tensor([[    0,  5117,  1733, 17...\n",
            "2258    {'input_ids': tensor([[    0,  2633,     7,   ...\n",
            "Name: tokenized_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Function to safely convert tokenized_text from string to dictionary\n",
        "def safe_convert(text):\n",
        "    try:\n",
        "        return json.loads(text.replace(\"'\", '\"'))  # Fix any formatting issues\n",
        "    except (ValueError, TypeError, json.JSONDecodeError):\n",
        "        return None  # Return None for corrupt entries\n",
        "\n",
        "# Function to safely tokenize text\n",
        "def re_tokenize_text(text):\n",
        "    if not isinstance(text, str):  # Ensure text is a string\n",
        "        return None\n",
        "    return tokenizer(text, padding=\"max_length\", truncation=True).data\n",
        "\n",
        "# Load the dataset again\n",
        "df_check = pd.read_csv(\"hinglish_pseudo_labeled.csv\")\n",
        "\n",
        "# Convert tokenized_text back to dictionary format\n",
        "df_check[\"tokenized_text\"] = df_check[\"tokenized_text\"].apply(safe_convert)\n",
        "\n",
        "# Drop rows where safe_convert couldn't fix the data\n",
        "df_check = df_check.dropna(subset=[\"tokenized_text\"]).reset_index(drop=True)\n",
        "\n",
        "# **Ensure cleaned_text is a string**\n",
        "df_check[\"cleaned_text\"] = df_check[\"cleaned_text\"].astype(str)\n",
        "\n",
        "# Apply tokenization again\n",
        "df_check[\"tokenized_text\"] = df_check[\"cleaned_text\"].apply(re_tokenize_text)\n",
        "\n",
        "# Save fixed dataset\n",
        "df_check.to_csv(\"hinglish_pseudo_labeled_fixed.csv\", index=False)\n",
        "print(\"✅ Tokenized text fixed! Saved as 'hinglish_pseudo_labeled_fixed.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d6hHdlB6nGr",
        "outputId": "a0e1c046-2f03-4de0-a688-55e53b0d7fac"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenized text fixed! Saved as 'hinglish_pseudo_labeled_fixed.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = \"hinglish_pseudo_labeled_fixed.csv\"\n",
        "df_debug = pd.read_csv(file_path)\n",
        "\n",
        "# Check missing values in key columns\n",
        "print(\"Missing Values Count:\")\n",
        "print(df_debug.isnull().sum())\n",
        "\n",
        "# Show rows where 'tokenized_text' is NaN\n",
        "df_missing = df_debug[df_debug[\"tokenized_text\"].isna()]\n",
        "print(\"\\n⚠️ Rows with missing tokenized_text:\")\n",
        "print(df_missing)\n",
        "\n",
        "# Show the first 5 values of tokenized_text\n",
        "print(\"\\n🛠 First 5 tokenized_text values:\")\n",
        "print(df_debug[\"tokenized_text\"].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-FGIk5q7-3_",
        "outputId": "1cf20516-da0c-4bf6-a06a-71e126145dae"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Count:\n",
            "publishedTimeText      0\n",
            "simpleText             0\n",
            "votes                  0\n",
            "author                 0\n",
            "isReply                0\n",
            "isHearted              0\n",
            "isPinned               0\n",
            "isPaid                 0\n",
            "paidAmount             0\n",
            "isSponsor              0\n",
            "sponsorshipMonths      0\n",
            "cleaned_text           0\n",
            "tokenized_text         0\n",
            "predicted_sentiment    0\n",
            "dtype: int64\n",
            "\n",
            "⚠️ Rows with missing tokenized_text:\n",
            "Empty DataFrame\n",
            "Columns: [publishedTimeText, simpleText, votes, author, isReply, isHearted, isPinned, isPaid, paidAmount, isSponsor, sponsorshipMonths, cleaned_text, tokenized_text, predicted_sentiment]\n",
            "Index: []\n",
            "\n",
            "🛠 First 5 tokenized_text values:\n",
            "Series([], Name: tokenized_text, dtype: object)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Check if tokenized_text is stored as a string instead of JSON\n",
        "def check_json_format(text):\n",
        "    try:\n",
        "        return json.loads(text.replace(\"'\", '\"'))  # Convert single quotes to double quotes\n",
        "    except json.JSONDecodeError:\n",
        "        return None  # Invalid format\n",
        "\n",
        "df_debug[\"fixed_tokenized_text\"] = df_debug[\"tokenized_text\"].apply(check_json_format)\n",
        "\n",
        "# Count invalid rows\n",
        "invalid_count = df_debug[\"fixed_tokenized_text\"].isna().sum()\n",
        "print(f\"\\n❌ Invalid tokenized_text rows: {invalid_count}\")\n",
        "\n",
        "# Drop invalid rows\n",
        "df_debug = df_debug.dropna(subset=[\"fixed_tokenized_text\"])\n",
        "df_debug.to_csv(\"hinglish_pseudo_labeled_fixed_v2.csv\", index=False)\n",
        "print(\"\\n✅ Fixed dataset saved as 'hinglish_pseudo_labeled_fixed_v2.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UWM9HH98Ova",
        "outputId": "a763a0c8-6684-4257-d3cb-5ad3b9df9111"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "❌ Invalid tokenized_text rows: 0\n",
            "\n",
            "✅ Fixed dataset saved as 'hinglish_pseudo_labeled_fixed_v2.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"hinglish_pseudo_labeled_fixed_v2.csv\"\n",
        "df_labeled = pd.read_csv(file_path)\n",
        "\n",
        "# Check again\n",
        "print(f\"✅ Reloaded dataset shape: {df_labeled.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVavoVdu8Wv6",
        "outputId": "b0e43e23-783b-4e06-bb7b-3f5d3a820129"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Reloaded dataset shape: (0, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset BEFORE preprocessing\n",
        "file_path = \"hinglish_pseudo_labeled_fixed.csv\"\n",
        "df_original = pd.read_csv(file_path)\n",
        "\n",
        "# Show dataset shape\n",
        "print(f\"🟢 Original dataset shape: {df_original.shape}\")\n",
        "\n",
        "# Show first few rows\n",
        "print(df_original.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15t4J8nz8neS",
        "outputId": "d9ebd355-2e8d-4829-d76d-deb7a53519a6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Original dataset shape: (0, 14)\n",
            "Empty DataFrame\n",
            "Columns: [publishedTimeText, simpleText, votes, author, isReply, isHearted, isPinned, isPaid, paidAmount, isSponsor, sponsorshipMonths, cleaned_text, tokenized_text, predicted_sentiment]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values\n",
        "print(\"\\n🔍 Missing values in each column:\")\n",
        "print(df_original.isnull().sum())\n",
        "\n",
        "# Check tokenized_text before cleaning\n",
        "print(\"\\n🛠 First 5 tokenized_text values BEFORE cleaning:\")\n",
        "print(df_original[\"tokenized_text\"].head())\n",
        "\n",
        "# Check predicted_sentiment before cleaning\n",
        "print(\"\\n🛠 First 5 predicted_sentiment values BEFORE cleaning:\")\n",
        "print(df_original[\"predicted_sentiment\"].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv-1rIL68pKu",
        "outputId": "c5650a19-451e-4e34-930d-73116ca56c4c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Missing values in each column:\n",
            "publishedTimeText      0\n",
            "simpleText             0\n",
            "votes                  0\n",
            "author                 0\n",
            "isReply                0\n",
            "isHearted              0\n",
            "isPinned               0\n",
            "isPaid                 0\n",
            "paidAmount             0\n",
            "isSponsor              0\n",
            "sponsorshipMonths      0\n",
            "cleaned_text           0\n",
            "tokenized_text         0\n",
            "predicted_sentiment    0\n",
            "dtype: int64\n",
            "\n",
            "🛠 First 5 tokenized_text values BEFORE cleaning:\n",
            "Series([], Name: tokenized_text, dtype: object)\n",
            "\n",
            "🛠 First 5 predicted_sentiment values BEFORE cleaning:\n",
            "Series([], Name: predicted_sentiment, dtype: object)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing tokenized_text with empty JSON\n",
        "df_original[\"tokenized_text\"] = df_original[\"tokenized_text\"].fillna(\"{}\")\n",
        "\n",
        "# Fill missing predicted_sentiment with \"neutral\"\n",
        "df_original[\"predicted_sentiment\"] = df_original[\"predicted_sentiment\"].fillna(\"neutral\")\n",
        "\n",
        "# Save fixed dataset\n",
        "df_original.to_csv(\"hinglish_fixed_final.csv\", index=False)\n",
        "print(\"✅ Fixed dataset saved as 'hinglish_fixed_final.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T_KISN48tG7",
        "outputId": "281cdd63-43bf-4386-936c-81848d2a5385"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fixed dataset saved as 'hinglish_fixed_final.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_labeled = pd.read_csv(\"hinglish_fixed_final.csv\")\n",
        "\n",
        "# Show dataset shape\n",
        "print(f\"✅ Reloaded dataset shape after fixing: {df_labeled.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpUj0gAX8xCM",
        "outputId": "67beda42-c655-4d37-ed08-6057754f317f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Reloaded dataset shape after fixing: (0, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"hinglish_pseudo_labeled.csv\"\n",
        "df_check = pd.read_csv(file_path)\n",
        "\n",
        "# Show dataset shape\n",
        "print(f\"🟢 Dataset shape BEFORE pseudo-labeling: {df_check.shape}\")\n",
        "\n",
        "# Show first few rows\n",
        "print(df_check.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOVlyGBn9Z0J",
        "outputId": "137d606c-f905-41ea-a8e0-2ff5a3a8e350"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Dataset shape BEFORE pseudo-labeling: (4309, 14)\n",
            "  publishedTimeText                                         simpleText  votes  \\\n",
            "0      23 hours ago  Underrated guest Sid Warrier, Positive energy ...    804   \n",
            "1      19 hours ago                        Asli Id se aao warrior bhai     23   \n",
            "2      17 hours ago                                                Yep      1   \n",
            "3      23 hours ago  No matter how big this show has gone, seeing S...    645   \n",
            "4      16 hours ago                                    100 % right 😍🤩🙌      4   \n",
            "\n",
            "                author  isReply  isHearted  isPinned  isPaid  paidAmount  \\\n",
            "0   @HumanityNotDoomed    False      False     False   False         NaN   \n",
            "1   @sarcasticaloo2220     True      False     False   False         NaN   \n",
            "2  @himangimahajan3631     True      False     False   False         NaN   \n",
            "3            @mesatin2    False      False     False   False         NaN   \n",
            "4      @mehtasanketd07     True      False     False   False         NaN   \n",
            "\n",
            "   isSponsor  sponsorshipMonths  \\\n",
            "0       True                1.0   \n",
            "1      False                NaN   \n",
            "2      False                NaN   \n",
            "3      False                NaN   \n",
            "4      False                NaN   \n",
            "\n",
            "                                        cleaned_text  \\\n",
            "0  underrated guest sid warrier positive energy n...   \n",
            "1                        asli id se aao warrior bhai   \n",
            "2                                                yep   \n",
            "3  matter big show gone seeing samay tanmay toget...   \n",
            "4                                              right   \n",
            "\n",
            "                                      tokenized_text  predicted_sentiment  \n",
            "0  {'input_ids': tensor([[     0,   1379,   2175,...                    1  \n",
            "1  {'input_ids': tensor([[     0,  50802,   3447,...                    1  \n",
            "2  {'input_ids': tensor([[   0,  113, 4517,    2,...                    1  \n",
            "3  {'input_ids': tensor([[    0, 26866,  6957,  7...                    1  \n",
            "4  {'input_ids': tensor([[   0, 7108,    2,    1,...                    1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if cleaned text exists\n",
        "if \"cleaned_text\" not in df_check.columns:\n",
        "    raise ValueError(\"❌ Column 'cleaned_text' is missing! Preprocessing failed.\")\n",
        "\n",
        "print(f\"🟢 Sample cleaned_text:\\n{df_check['cleaned_text'].head()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDdM45OQ9b8a",
        "outputId": "4665f8e6-451d-4c73-e658-dadd85885f44"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Sample cleaned_text:\n",
            "0    underrated guest sid warrier positive energy n...\n",
            "1                          asli id se aao warrior bhai\n",
            "2                                                  yep\n",
            "3    matter big show gone seeing samay tanmay toget...\n",
            "4                                                right\n",
            "Name: cleaned_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "\n",
        "# Function to safely convert tokenized_text\n",
        "def safe_convert(text):\n",
        "    try:\n",
        "        return eval(text, {\"tensor\": torch.tensor}) if isinstance(text, str) else text\n",
        "    except (SyntaxError, ValueError, NameError):\n",
        "        return None  # Return None for corrupt entries\n",
        "\n",
        "# Apply safe conversion\n",
        "df_check[\"tokenized_text\"] = df_check[\"tokenized_text\"].apply(safe_convert)\n",
        "\n",
        "# Drop rows where conversion failed\n",
        "df_check = df_check.dropna(subset=[\"tokenized_text\"])\n",
        "\n",
        "# Save fixed dataset\n",
        "df_check.to_csv(\"hinglish_fixed_final.csv\", index=False)\n",
        "print(\"✅ Tokenized text fixed! Saved as 'hinglish_fixed_final.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM6lC4qP-I-n",
        "outputId": "ea0fcaf7-bfef-485c-9fb5-bc21bcc15cb5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenized text fixed! Saved as 'hinglish_fixed_final.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load fixed dataset\n",
        "df_labeled = pd.read_csv(\"hinglish_fixed_final.csv\")\n",
        "\n",
        "# Check dataset shape & sample rows\n",
        "print(f\"✅ Reloaded dataset shape: {df_labeled.shape}\")\n",
        "df_labeled.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "U6nHII7U-mb0",
        "outputId": "16576b09-b853-4c09-eac8-48e815c8deb5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Reloaded dataset shape: (4309, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  publishedTimeText                                         simpleText  votes  \\\n",
              "0      23 hours ago  Underrated guest Sid Warrier, Positive energy ...    804   \n",
              "1      19 hours ago                        Asli Id se aao warrior bhai     23   \n",
              "2      17 hours ago                                                Yep      1   \n",
              "3      23 hours ago  No matter how big this show has gone, seeing S...    645   \n",
              "4      16 hours ago                                    100 % right 😍🤩🙌      4   \n",
              "\n",
              "                author  isReply  isHearted  isPinned  isPaid  paidAmount  \\\n",
              "0   @HumanityNotDoomed    False      False     False   False         NaN   \n",
              "1   @sarcasticaloo2220     True      False     False   False         NaN   \n",
              "2  @himangimahajan3631     True      False     False   False         NaN   \n",
              "3            @mesatin2    False      False     False   False         NaN   \n",
              "4      @mehtasanketd07     True      False     False   False         NaN   \n",
              "\n",
              "   isSponsor  sponsorshipMonths  \\\n",
              "0       True                1.0   \n",
              "1      False                NaN   \n",
              "2      False                NaN   \n",
              "3      False                NaN   \n",
              "4      False                NaN   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  underrated guest sid warrier positive energy n...   \n",
              "1                        asli id se aao warrior bhai   \n",
              "2                                                yep   \n",
              "3  matter big show gone seeing samay tanmay toget...   \n",
              "4                                              right   \n",
              "\n",
              "                                      tokenized_text  predicted_sentiment  \n",
              "0  {'input_ids': tensor([[     0,   1379,   2175,...                    1  \n",
              "1  {'input_ids': tensor([[     0,  50802,   3447,...                    1  \n",
              "2  {'input_ids': tensor([[   0,  113, 4517,    2,...                    1  \n",
              "3  {'input_ids': tensor([[    0, 26866,  6957,  7...                    1  \n",
              "4  {'input_ids': tensor([[   0, 7108,    2,    1,...                    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-423ab0d0-a102-4452-ac16-e4473e9e75ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publishedTimeText</th>\n",
              "      <th>simpleText</th>\n",
              "      <th>votes</th>\n",
              "      <th>author</th>\n",
              "      <th>isReply</th>\n",
              "      <th>isHearted</th>\n",
              "      <th>isPinned</th>\n",
              "      <th>isPaid</th>\n",
              "      <th>paidAmount</th>\n",
              "      <th>isSponsor</th>\n",
              "      <th>sponsorshipMonths</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>predicted_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23 hours ago</td>\n",
              "      <td>Underrated guest Sid Warrier, Positive energy ...</td>\n",
              "      <td>804</td>\n",
              "      <td>@HumanityNotDoomed</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>underrated guest sid warrier positive energy n...</td>\n",
              "      <td>{'input_ids': tensor([[     0,   1379,   2175,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19 hours ago</td>\n",
              "      <td>Asli Id se aao warrior bhai</td>\n",
              "      <td>23</td>\n",
              "      <td>@sarcasticaloo2220</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>asli id se aao warrior bhai</td>\n",
              "      <td>{'input_ids': tensor([[     0,  50802,   3447,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17 hours ago</td>\n",
              "      <td>Yep</td>\n",
              "      <td>1</td>\n",
              "      <td>@himangimahajan3631</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yep</td>\n",
              "      <td>{'input_ids': tensor([[   0,  113, 4517,    2,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23 hours ago</td>\n",
              "      <td>No matter how big this show has gone, seeing S...</td>\n",
              "      <td>645</td>\n",
              "      <td>@mesatin2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>matter big show gone seeing samay tanmay toget...</td>\n",
              "      <td>{'input_ids': tensor([[    0, 26866,  6957,  7...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16 hours ago</td>\n",
              "      <td>100 % right 😍🤩🙌</td>\n",
              "      <td>4</td>\n",
              "      <td>@mehtasanketd07</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>right</td>\n",
              "      <td>{'input_ids': tensor([[   0, 7108,    2,    1,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-423ab0d0-a102-4452-ac16-e4473e9e75ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-423ab0d0-a102-4452-ac16-e4473e9e75ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-423ab0d0-a102-4452-ac16-e4473e9e75ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4ea6eed-b126-48b8-8d7b-32b8ef7e4864\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4ea6eed-b126-48b8-8d7b-32b8ef7e4864')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4ea6eed-b126-48b8-8d7b-32b8ef7e4864 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_labeled",
              "summary": "{\n  \"name\": \"df_labeled\",\n  \"rows\": 4309,\n  \"fields\": [\n    {\n      \"column\": \"publishedTimeText\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 74,\n        \"samples\": [\n          \"13 hours ago\",\n          \"2 minutes ago\",\n          \"18 hours ago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"simpleText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4062,\n        \"samples\": [\n          \"Itna views kyun hai\",\n          \"YouTube let that man earn money out of it...this kind of quality can't be delivered by anyone in India\",\n          \"https://thesocialnews24.blogspot.com/2024/11/online-earning-5.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 0,\n        \"max\": 804,\n        \"num_unique_values\": 64,\n        \"samples\": [\n          22,\n          15,\n          804\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3748,\n        \"samples\": [\n          \"@kartik3102\",\n          \"@parmindersingh2245\",\n          \"@gatik9593\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isReply\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isHearted\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isPinned\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isPaid\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paidAmount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isSponsor\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sponsorshipMonths\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7956312254958444,\n        \"min\": 0.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 12,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3537,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3538,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"\\n🔍 Missing values in each column:\")\n",
        "print(df_labeled.isnull().sum())\n",
        "\n",
        "# If empty, stop and debug\n",
        "if df_labeled.empty:\n",
        "    raise ValueError(\"❌ No valid data left after preprocessing! Check tokenized_text format.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hpWfn1v-s6K",
        "outputId": "eb1d4e8a-0ef8-4a80-ab8f-1d2e388a423a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Missing values in each column:\n",
            "publishedTimeText         0\n",
            "simpleText                0\n",
            "votes                     0\n",
            "author                    1\n",
            "isReply                   0\n",
            "isHearted                 0\n",
            "isPinned                  0\n",
            "isPaid                    0\n",
            "paidAmount             4309\n",
            "isSponsor                 0\n",
            "sponsorshipMonths      3814\n",
            "cleaned_text            504\n",
            "tokenized_text            0\n",
            "predicted_sentiment       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Fill missing 'cleaned_text' values with an empty string to avoid errors\n",
        "df_labeled[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
        "\n",
        "# Drop rows where tokenized_text is missing (these can't be used for training)\n",
        "df_labeled = df_labeled.dropna(subset=[\"tokenized_text\"])\n",
        "\n",
        "# Ensure 'predicted_sentiment' column has valid numerical labels\n",
        "sentiment_map = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
        "df_labeled[\"label\"] = df_labeled[\"predicted_sentiment\"].map(sentiment_map)\n",
        "\n",
        "# Drop any rows where sentiment mapping failed\n",
        "df_labeled = df_labeled.dropna(subset=[\"label\"])\n",
        "\n",
        "# Convert 'label' to integer type\n",
        "df_labeled[\"label\"] = df_labeled[\"label\"].astype(int)\n",
        "\n",
        "# Save the cleaned dataset\n",
        "df_labeled.to_csv(\"hinglish_final_cleaned.csv\", index=False)\n",
        "\n",
        "# Check the dataset shape after cleaning\n",
        "print(f\"✅ After cleaning, dataset shape: {df_labeled.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omZS0BI9-u3r",
        "outputId": "5e084324-cbae-48fc-a81b-606f22c26129"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ After cleaning, dataset shape: (0, 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-f922410eea1d>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_labeled[\"cleaned_text\"].fillna(\"\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataset Shape: {df_labeled.shape}\")\n",
        "print(df_labeled.head())  # Display the first few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqv0j9IIAAEt",
        "outputId": "9aae5196-2415-4486-8f3b-4b68dc5856c4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (0, 15)\n",
            "Empty DataFrame\n",
            "Columns: [publishedTimeText, simpleText, votes, author, isReply, isHearted, isPinned, isPaid, paidAmount, isSponsor, sponsorshipMonths, cleaned_text, tokenized_text, predicted_sentiment, label]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔍 Missing values in each column:\\n\", df_labeled.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a1r0ekMAHq1",
        "outputId": "65edfe1f-7ada-422c-dfb0-7297ec8f431a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Missing values in each column:\n",
            " publishedTimeText      0\n",
            "simpleText             0\n",
            "votes                  0\n",
            "author                 0\n",
            "isReply                0\n",
            "isHearted              0\n",
            "isPinned               0\n",
            "isPaid                 0\n",
            "paidAmount             0\n",
            "isSponsor              0\n",
            "sponsorshipMonths      0\n",
            "cleaned_text           0\n",
            "tokenized_text         0\n",
            "predicted_sentiment    0\n",
            "label                  0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_map = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
        "\n",
        "# Convert sentiment labels\n",
        "df_labeled[\"label\"] = df_labeled[\"predicted_sentiment\"].map(sentiment_map)\n",
        "\n",
        "# Drop rows where sentiment mapping failed\n",
        "df_labeled = df_labeled.dropna(subset=[\"label\"])\n",
        "\n",
        "# Convert to integer type\n",
        "df_labeled[\"label\"] = df_labeled[\"label\"].astype(int)\n",
        "\n",
        "# Ensure text is properly formatted\n",
        "df_labeled[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
        "df_labeled = df_labeled.dropna(subset=[\"tokenized_text\"])  # Drop empty tokenized rows\n",
        "\n",
        "# Save the cleaned dataset\n",
        "df_labeled.to_csv(\"hinglish_final_cleaned.csv\", index=False)\n",
        "\n",
        "print(f\"✅ After re-cleaning, dataset shape: {df_labeled.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc_zBvFhAPpj",
        "outputId": "3786c6b3-dbf5-478a-e5eb-770159c04784"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ After re-cleaning, dataset shape: (0, 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-d3aff3c18270>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_labeled[\"cleaned_text\"].fillna(\"\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the actual Hinglish dataset (replace with correct filename if needed)\n",
        "file_path = \"/content/comments INDIA'S GOT LATENT  EP 10 ft. Raghu Ram _@tanmaybhat_  _@Sidwarrier_ buSdqtdn_4I.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(f\"✅ Original dataset loaded! Shape: {df.shape}\")\n",
        "print(df.head())  # Show first few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-lNe_2gAzYG",
        "outputId": "61dba7d6-81fc-4f97-de7c-a6d1a276a0e3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Original dataset loaded! Shape: (4309, 11)\n",
            "  publishedTimeText                                         simpleText  votes  \\\n",
            "0      23 hours ago  Underrated guest Sid Warrier, Positive energy ...    804   \n",
            "1      19 hours ago                        Asli Id se aao warrior bhai     23   \n",
            "2      17 hours ago                                                Yep      1   \n",
            "3      23 hours ago  No matter how big this show has gone, seeing S...    645   \n",
            "4      16 hours ago                                    100 % right 😍🤩🙌      4   \n",
            "\n",
            "                author  isReply  isHearted  isPinned  isPaid  paidAmount  \\\n",
            "0   @HumanityNotDoomed    False      False     False   False         NaN   \n",
            "1   @sarcasticaloo2220     True      False     False   False         NaN   \n",
            "2  @himangimahajan3631     True      False     False   False         NaN   \n",
            "3            @mesatin2    False      False     False   False         NaN   \n",
            "4      @mehtasanketd07     True      False     False   False         NaN   \n",
            "\n",
            "   isSponsor  sponsorshipMonths  \n",
            "0       True                1.0  \n",
            "1      False                NaN  \n",
            "2      False                NaN  \n",
            "3      False                NaN  \n",
            "4      False                NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔍 Available columns:\", df.columns)\n",
        "print(\"🔍 Sample comments:\\n\", df[\"simpleText\"].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EoaJiYkA5Ka",
        "outputId": "a50adcd9-78e1-4d87-bedc-8e377a212e40"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Available columns: Index(['publishedTimeText', 'simpleText', 'votes', 'author', 'isReply',\n",
            "       'isHearted', 'isPinned', 'isPaid', 'paidAmount', 'isSponsor',\n",
            "       'sponsorshipMonths'],\n",
            "      dtype='object')\n",
            "🔍 Sample comments:\n",
            " 0    Underrated guest Sid Warrier, Positive energy ...\n",
            "1                          Asli Id se aao warrior bhai\n",
            "2                                                  Yep\n",
            "3    No matter how big this show has gone, seeing S...\n",
            "4                                      100 % right 😍🤩🙌\n",
            "Name: simpleText, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a simple text cleaner function\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):  # Check if text is valid\n",
        "        text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  # Remove special characters\n",
        "        text = text.lower().strip()  # Convert to lowercase\n",
        "        return text\n",
        "    return \"\"  # If NaN or missing, return empty string\n",
        "\n",
        "df[\"cleaned_text\"] = df[\"simpleText\"].apply(clean_text)\n",
        "\n",
        "print(\"✅ Text cleaning complete! Sample:\\n\", df[[\"simpleText\", \"cleaned_text\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUw_JodjA99j",
        "outputId": "5802e082-058f-44f3-8f57-7a61974a8cd4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Text cleaning complete! Sample:\n",
            "                                           simpleText  \\\n",
            "0  Underrated guest Sid Warrier, Positive energy ...   \n",
            "1                        Asli Id se aao warrior bhai   \n",
            "2                                                Yep   \n",
            "3  No matter how big this show has gone, seeing S...   \n",
            "4                                    100 % right 😍🤩🙌   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  underrated guest sid warrier positive energy n...  \n",
            "1                        asli id se aao warrior bhai  \n",
            "2                                                yep  \n",
            "3  no matter how big this show has gone seeing sa...  \n",
            "4                                         100  right  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load a multilingual tokenizer (XLM-R, mBERT, etc.)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Tokenize the text\n",
        "df[\"tokenized_text\"] = df[\"cleaned_text\"].apply(lambda x: tokenizer(x, padding=\"max_length\", truncation=True).data)\n",
        "\n",
        "print(\"✅ Tokenization complete! Sample:\\n\", df[[\"cleaned_text\", \"tokenized_text\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC3tXrnuBBrA",
        "outputId": "09307cf7-6254-46d9-ce97-e742ee842ef7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenization complete! Sample:\n",
            "                                         cleaned_text  \\\n",
            "0  underrated guest sid warrier positive energy n...   \n",
            "1                        asli id se aao warrior bhai   \n",
            "2                                                yep   \n",
            "3  no matter how big this show has gone seeing sa...   \n",
            "4                                         100  right   \n",
            "\n",
            "                                      tokenized_text  \n",
            "0  {'input_ids': [0, 1379, 2175, 297, 121399, 78,...  \n",
            "1  {'input_ids': [0, 50802, 3447, 40, 10, 11, 31,...  \n",
            "2  {'input_ids': [0, 113, 4517, 2, 1, 1, 1, 1, 1,...  \n",
            "3  {'input_ids': [0, 110, 26866, 3642, 6957, 903,...  \n",
            "4  {'input_ids': [0, 805, 7108, 2, 1, 1, 1, 1, 1,...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"predicted_sentiment\" not in df.columns:\n",
        "    print(\"❌ No sentiment labels found! Generating pseudo-labels...\")\n",
        "    df[\"predicted_sentiment\"] = 1  # Default neutral\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCh_OR2OBIeU",
        "outputId": "b358e3fc-72bc-4252-e82f-ff53f7c8e25f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ No sentiment labels found! Generating pseudo-labels...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"hinglish_cleaned.csv\", index=False)\n",
        "print(\"✅ Hinglish dataset saved as 'hinglish_cleaned.csv'! Ready for training.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NzNEJ_nBKU4",
        "outputId": "42da89b8-f50c-41cf-f593-6866438f7268"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hinglish dataset saved as 'hinglish_cleaned.csv'! Ready for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = HinglishDataset(df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "print(f\"✅ Training dataset loaded! Total samples: {len(df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDkw4Yn_BQCk",
        "outputId": "a0c328e6-4e69-466d-d214-107d451eeb99"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training dataset loaded! Total samples: 4309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the cleaned dataset\n",
        "file_path = \"hinglish_cleaned.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(f\"✅ Reloaded dataset shape: {df.shape}\")\n",
        "print(df.head())  # Show first few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBq1IEzgCjnm",
        "outputId": "e7e31e63-a1e3-440b-9062-843ca4a7954b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Reloaded dataset shape: (4309, 14)\n",
            "  publishedTimeText                                         simpleText  votes  \\\n",
            "0      23 hours ago  Underrated guest Sid Warrier, Positive energy ...    804   \n",
            "1      19 hours ago                        Asli Id se aao warrior bhai     23   \n",
            "2      17 hours ago                                                Yep      1   \n",
            "3      23 hours ago  No matter how big this show has gone, seeing S...    645   \n",
            "4      16 hours ago                                    100 % right 😍🤩🙌      4   \n",
            "\n",
            "                author  isReply  isHearted  isPinned  isPaid  paidAmount  \\\n",
            "0   @HumanityNotDoomed    False      False     False   False         NaN   \n",
            "1   @sarcasticaloo2220     True      False     False   False         NaN   \n",
            "2  @himangimahajan3631     True      False     False   False         NaN   \n",
            "3            @mesatin2    False      False     False   False         NaN   \n",
            "4      @mehtasanketd07     True      False     False   False         NaN   \n",
            "\n",
            "   isSponsor  sponsorshipMonths  \\\n",
            "0       True                1.0   \n",
            "1      False                NaN   \n",
            "2      False                NaN   \n",
            "3      False                NaN   \n",
            "4      False                NaN   \n",
            "\n",
            "                                        cleaned_text  \\\n",
            "0  underrated guest sid warrier positive energy n...   \n",
            "1                        asli id se aao warrior bhai   \n",
            "2                                                yep   \n",
            "3  no matter how big this show has gone seeing sa...   \n",
            "4                                         100  right   \n",
            "\n",
            "                                      tokenized_text  predicted_sentiment  \n",
            "0  {'input_ids': [0, 1379, 2175, 297, 121399, 78,...                    1  \n",
            "1  {'input_ids': [0, 50802, 3447, 40, 10, 11, 31,...                    1  \n",
            "2  {'input_ids': [0, 113, 4517, 2, 1, 1, 1, 1, 1,...                    1  \n",
            "3  {'input_ids': [0, 110, 26866, 3642, 6957, 903,...                    1  \n",
            "4  {'input_ids': [0, 805, 7108, 2, 1, 1, 1, 1, 1,...                    1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "\n",
        "# Function to safely convert tokenized_text back to dictionary\n",
        "def convert_tokenized_text(text):\n",
        "    try:\n",
        "        return json.loads(text.replace(\"'\", '\"'))  # Fix string format\n",
        "    except (json.JSONDecodeError, TypeError):\n",
        "        return None  # Return None for corrupt entries\n",
        "\n",
        "df[\"tokenized_text\"] = df[\"tokenized_text\"].apply(convert_tokenized_text)\n",
        "\n",
        "# Drop rows where tokenized_text couldn't be fixed\n",
        "df = df.dropna(subset=[\"tokenized_text\"])\n",
        "\n",
        "print(\"✅ Tokenized text successfully converted back!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6GuqvcACuWK",
        "outputId": "0fa75e4e-1733-4d88-cff4-b468e204cc81"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenized text successfully converted back!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define a PyTorch dataset class\n",
        "class HinglishDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(item[\"tokenized_text\"][\"input_ids\"]),\n",
        "            \"attention_mask\": torch.tensor(item[\"tokenized_text\"][\"attention_mask\"]),\n",
        "            \"label\": torch.tensor(int(item[\"predicted_sentiment\"]))\n",
        "        }\n",
        "\n",
        "# Create dataset & dataloader\n",
        "train_dataset = HinglishDataset(df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "print(f\"✅ Training dataset loaded! Total samples: {len(df)}\")\n"
      ],
      "metadata": {
        "id": "1zEt-4VtC11o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "train_dataset = HinglishDataset(df_labeled)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "print(f\"✅ Training dataset loaded! Total samples: {len(df_labeled)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Bg2doxP1AWcH",
        "outputId": "8bdb608e-5966-4359-fb61-4d2a6f65572d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f263b937c934>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHinglishDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_labeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Training dataset loaded! Total samples: {len(df_labeled)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define Hinglish Dataset class\n",
        "class HinglishDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(eval(item[\"tokenized_text\"])[\"input_ids\"]).squeeze(),\n",
        "            \"attention_mask\": torch.tensor(eval(item[\"tokenized_text\"])[\"attention_mask\"]).squeeze(),\n",
        "            \"label\": torch.tensor(item[\"label\"], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = HinglishDataset(df_labeled)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "print(f\"✅ Training dataset loaded! Total samples: {len(df_labeled)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3Dp-DBWx_wXk",
        "outputId": "d2d40bab-60be-40a0-e43f-b33dfa6b1e1b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-e7d3cadb35c3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Create DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHinglishDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_labeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Training dataset loaded! Total samples: {len(df_labeled)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ensure dataset has sentences before labeling\n",
        "if df_check.empty:\n",
        "    raise ValueError(\"❌ Dataset is empty! Cannot pseudo-label.\")\n",
        "\n",
        "# Tokenize sentences\n",
        "df_check[\"tokenized_text\"] = df_check[\"cleaned_text\"].apply(tokenize_text)\n",
        "\n",
        "# Create dataset & dataloader\n",
        "unlabeled_dataset = HinglishDataset(df_check)\n",
        "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Predict labels\n",
        "df_check[\"predicted_sentiment\"] = predict_sentiment(model, unlabeled_dataloader)\n",
        "\n",
        "# Save new labeled dataset\n",
        "df_check.to_csv(\"hinglish_fixed_final.csv\", index=False)\n",
        "print(\"✅ Pseudo-labeling fixed! Saved as 'hinglish_fixed_final.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "UMYfnWqD9fml",
        "outputId": "540efa22-a1b9-4fd6-ad40-543544b2ff45"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-7e510764e31f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Tokenize sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_check\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokenized_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_check\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cleaned_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create dataset & dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-bdbf0a402ebf>\u001b[0m in \u001b[0;36mtokenize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Tokenize text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Apply tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2866\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2868\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2870\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2929\u001b[0m                 \u001b[0;34m\"text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Load the fixed dataset\n",
        "file_path = \"hinglish_pseudo_labeled_fixed.csv\"\n",
        "df_labeled = pd.read_csv(file_path)\n",
        "\n",
        "# Convert predicted sentiment labels to integers\n",
        "df_labeled.rename(columns={\"predicted_sentiment\": \"label\"}, inplace=True)\n",
        "df_labeled[\"label\"] = df_labeled[\"label\"].astype(int)\n",
        "\n",
        "# HinglishDataset class (Ensure correct tensor data type)\n",
        "class HinglishDataset(Dataset):\n",
        "    def __init__(self, dataframe, labeled=True):\n",
        "        self.data = dataframe\n",
        "        self.labeled = labeled  # Flag to check if dataset has labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        tokenized_text = json.loads(item[\"tokenized_text\"].replace(\"'\", '\"'))  # Ensure JSON format\n",
        "\n",
        "        data = {\n",
        "            \"input_ids\": torch.tensor(tokenized_text[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(tokenized_text[\"attention_mask\"], dtype=torch.long),\n",
        "        }\n",
        "        if self.labeled:\n",
        "            data[\"labels\"] = torch.tensor(item[\"label\"], dtype=torch.long)\n",
        "\n",
        "        return data\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_dataset = HinglishDataset(df_labeled, labeled=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "print(f\"✅ Training dataset loaded! Total samples: {len(df_labeled)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3kXvg2px7YEP",
        "outputId": "8f8890ca-ccac-4c10-8b5b-82ef28bf9e0a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-99f75495acda>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Create DataLoader for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHinglishDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Training dataset loaded! Total samples: {len(df_labeled)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if DataFrame is empty after preprocessing\n",
        "if df_labeled.empty:\n",
        "    raise ValueError(\"❌ No valid data left after preprocessing! Check tokenized_text format.\")\n",
        "\n",
        "# Proceed only if data exists\n",
        "train_dataset = HinglishDataset(df_labeled, labeled=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Retrain the model\n",
        "train_model(model, train_dataloader, optimizer, loss_fn, lr_scheduler, num_epochs=5)\n",
        "\n",
        "print(\"✅ Retraining complete! The model is now updated with pseudo-labeled data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ePCAIiNQ6WC-",
        "outputId": "77587748-f9c2-4ca4-c7e9-cf0e509e4de6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "❌ No valid data left after preprocessing! Check tokenized_text format.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-93041a5e8f33>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check if DataFrame is empty after preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf_labeled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ No valid data left after preprocessing! Check tokenized_text format.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Proceed only if data exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ❌ No valid data left after preprocessing! Check tokenized_text format."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "\n",
        "# Function to safely convert tokenized_text\n",
        "def safe_convert(text):\n",
        "    try:\n",
        "        return json.loads(text.replace(\"'\", '\"'))  # Replace single quotes with double quotes for JSON\n",
        "    except (ValueError, TypeError, json.JSONDecodeError):\n",
        "        return None  # Return None for corrupt entries\n",
        "\n",
        "# Load pseudo-labeled dataset\n",
        "file_path = \"hinglish_pseudo_labeled.csv\"\n",
        "df_labeled = pd.read_csv(file_path)\n",
        "\n",
        "# Convert tokenized_text safely\n",
        "df_labeled[\"tokenized_text\"] = df_labeled[\"tokenized_text\"].apply(safe_convert)\n",
        "\n",
        "# Drop rows with invalid tokenized_text\n",
        "df_labeled = df_labeled.dropna(subset=[\"tokenized_text\"]).reset_index(drop=True)\n",
        "\n",
        "# Rename 'predicted_sentiment' as 'label' for training\n",
        "df_labeled.rename(columns={\"predicted_sentiment\": \"label\"}, inplace=True)\n",
        "\n",
        "# Convert labels to integers\n",
        "df_labeled[\"label\"] = df_labeled[\"label\"].astype(int)\n",
        "\n",
        "# Fix HinglishDataset class to ensure correct tensor data type\n",
        "class HinglishDataset(Dataset):\n",
        "    def __init__(self, dataframe, labeled=True):\n",
        "        self.data = dataframe\n",
        "        self.labeled = labeled  # Flag to check if dataset has labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "\n",
        "        tokenized_text = item[\"tokenized_text\"]\n",
        "\n",
        "        data = {\n",
        "            \"input_ids\": torch.tensor(tokenized_text[\"input_ids\"], dtype=torch.long),  # Fix dtype\n",
        "            \"attention_mask\": torch.tensor(tokenized_text[\"attention_mask\"], dtype=torch.long),  # Fix dtype\n",
        "        }\n",
        "        if self.labeled:\n",
        "            data[\"labels\"] = torch.tensor(item[\"label\"], dtype=torch.long)  # Fix dtype\n",
        "\n",
        "        return data\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_dataset = HinglishDataset(df_labeled, labeled=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Retrain the model\n",
        "train_model(model, train_dataloader, optimizer, loss_fn, lr_scheduler, num_epochs=5)\n",
        "\n",
        "print(\"✅ Retraining complete! The model is now updated with pseudo-labeled data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "aRs63ZQz5Gf4",
        "outputId": "857a56f3-1995-45f8-b570-c80fabf7d38c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-11b3750a7bdf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Create DataLoader for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHinglishDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Retrain the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    }
  ]
}